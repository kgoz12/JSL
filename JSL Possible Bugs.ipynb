{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.executable\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"JAVA_HOME\"] = \"/Library/Java/JavaVirtualMachines/adoptopenjdk-8.jdk/Contents/Home\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark # only run after findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder\\\n",
    ".appName(\"Spark NLP\")\\\n",
    ".master(\"local[4]\")\\\n",
    ".config(\"spark.driver.memory\",\"16G\")\\\n",
    ".config(\"spark.driver.maxResultSize\", \"2G\")\\\n",
    ".config(\"spark.jars.packages\", \"com.johnsnowlabs.nlp:spark-nlp_2.11:2.5.4\")\\\n",
    ".config(\"spark.kryoserializer.buffer.max\",\"1000M\")\\\n",
    ".getOrCreate()\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sc\n",
    "import sklearn as sk\n",
    "import re\n",
    "\n",
    "from pyspark.ml.feature import CountVectorizer, Tokenizer, RegexTokenizer, StopWordsRemover\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.stat import Summarizer\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import StringType, StructField, StructType, BooleanType, ArrayType, IntegerType, MapType, FloatType\n",
    "\n",
    "import sparknlp\n",
    "from sparknlp.pretrained import PretrainedPipeline\n",
    "from sparknlp.base import *\n",
    "from sparknlp.annotator import *\n",
    "from sparknlp.embeddings import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.5.4'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparknlp.version()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+\n",
      "|rowkey|                text|\n",
      "+------+--------------------+\n",
      "|     1|A dish is also be...|\n",
      "|     2|To me it seems ab...|\n",
      "|     3|Many kilns have e...|\n",
      "|     4|Pieces which have...|\n",
      "|     5|When the pieces a...|\n",
      "+------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create a toy dataframe with text I'd like to tinker with\n",
    "\n",
    "df = spark.createDataFrame([['1', 'A dish is also best thrown on a bat. No cylinder is made. The first step is to centre a flat disc of large diameter. The fingers are used as before to press down in the middle and are then drawn towards the edge preceded by a ridge of clay which gradually increases the diameter at each trip.'],                            \n",
    "                            ['2', 'To me it seems absurd to present someone who is only a beginner with anything heavier to throw than one pound of clay. In fact I would tend to commence with even less. This is because the problem of controlling and centering increases rapidly as the size of the lump becomes heavier. Long, tedious attempts to master a big piece only lead to frustration, disappointment, and material which soon becomes too wet to manage anyway. In my opinion, a smaller wheel and less powerful motor is quite sufficient for most students and for many serious workers too.'],\n",
    "                            ['3', 'Many kilns have elements running along the bottom as well as the sides and sometimes in the door and back. Even so, pots on the top shelf can easily be far cooler than those placed lower down in the kiln, If one superimposes on this additional discrepancy the ones we have just examined, it is easy to visualise that within the same firing chamber quite startling variations in temperature can occur.'],\n",
    "                            ['4', 'Pieces which have been painted with slip can usually be picked up with reasonable safety, provided the hands are clean and free of dust, but any which have had pottery colours applied to the surface should be held at points away from the pigment or from the inside. If a colour is inadvertantly smudged the damage can aften be repaired; use a razor blade to scratch away the smear and then very carefully fill in again with the paint brush. Where a slipped surface is chipped or otherwise marked the piece at this stage will be too dry to correct with slip, and one can either try and make good straightaway with the nearest available pottery colour or wait until after the biscuit firing and use colour before dipping the piece in glaze.'],\n",
    "                            ['5', 'When the pieces are being arranged, it is as well to remember that shelves should be as small as possible, consistent with their usefulness in supporting the ware. This is to avoid splitting the chamber into separate compartments. It is far better to allow the pots to overhang the edges a little and so permit the heat to circulate freely. A twelve inch square internal measurement will do best with a shelf no bigger than ten by ten.']],\n",
    "                           ['rowkey', 'text'])\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame[summary: string, rowkey: string, text: string]\n",
      "(5, 2)\n"
     ]
    }
   ],
   "source": [
    "# view summary of data frame\n",
    "print(df.describe())\n",
    "print((df.count(), len(df.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# document assember \n",
    "document_assembler = sparknlp.DocumentAssembler()\\\n",
    ".setInputCol(\"text\")\\\n",
    ".setOutputCol(\"document\")\\\n",
    ".setCleanupMode(\"shrink_full\")\n",
    "\n",
    "# tokenizer \n",
    "tokenizer = sparknlp.annotator.Tokenizer()\\\n",
    ".setInputCols(\"document\")\\\n",
    ".setOutputCol(\"token\")\\\n",
    ".setTargetPattern(\"\\S+\")\\\n",
    ".addInfixPattern(\"(/)(\\\\p{Alpha}+)\")\\\n",
    ".addInfixPattern(\"(\\\\p{Alpha}+)(/)(\\\\p{Alpha}+)\")\\\n",
    ".addInfixPattern(\"(\\\\p{Alpha}+)(\\\\.)(\\\\p{Upper}\\\\p{Alpha}+)\")\\\n",
    ".addInfixPattern(\"(.+)(\\\\.)\\\\z\")\\\n",
    ".addInfixPattern(\"(.+)([,:/])\\\\z\")\\\n",
    ".addInfixPattern(\"(\\\\()(.+)(\\\\))\")\\\n",
    ".addInfixPattern(\"(\\\\()(.+)\")\\\n",
    ".addInfixPattern(\"(.+)(\\\\))\")\\\n",
    ".addException(\"New York\")\n",
    "\n",
    "# context dependent spell checker\n",
    "spell_checker = sparknlp.annotator.ContextSpellCheckerApproach()\\\n",
    ".setInputCols([\"token\"])\\\n",
    ".setOutputCol(\"spell\")\\\n",
    ".setLanguageModelClasses(1000)\\\n",
    ".setWordMaxDistance(6)\\\n",
    ".setEpochs(2)\n",
    "\n",
    "# pipeline\n",
    "pipeline =  Pipeline().setStages([document_assembler,\n",
    "                                          tokenizer, \n",
    "                                          spell_checker\n",
    "                                         ])\n",
    "\n",
    "model = pipeline.fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'document': [\"My friend moved to New York. She likes it. Frank visited New York, and didn't like it.\"],\n",
       " 'token': ['My',\n",
       "  'friend',\n",
       "  'moved',\n",
       "  'to',\n",
       "  'New York.',\n",
       "  'She',\n",
       "  'likes',\n",
       "  'it',\n",
       "  '.',\n",
       "  'Frank',\n",
       "  'visited',\n",
       "  'New York,',\n",
       "  'and',\n",
       "  \"didn't\",\n",
       "  'like',\n",
       "  'it',\n",
       "  '.'],\n",
       " 'spell': ['to',\n",
       "  'and',\n",
       "  'have',\n",
       "  'to',\n",
       "  'New York.',\n",
       "  'the',\n",
       "  'is',\n",
       "  'it',\n",
       "  '.',\n",
       "  'and',\n",
       "  'is',\n",
       "  'New York,',\n",
       "  'and',\n",
       "  'it',\n",
       "  'the',\n",
       "  'it',\n",
       "  '.']}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# punctuation is not tokenized separately from the bi-grams in the exception list\n",
    "# Is this a bug?\n",
    "lp = LightPipeline(model)\n",
    "lp.annotate(\"My friend moved to New York. She likes it. Frank visited New York, and didn't like it.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentence detector\n",
    "sentence_detector = SentenceDetector()\\\n",
    ".setInputCols(\"document\")\\\n",
    ".setOutputCol(\"sentence\")\n",
    "\n",
    "# tokenizer \n",
    "tokenizerS = sparknlp.annotator.Tokenizer()\\\n",
    ".setInputCols(\"sentence\")\\\n",
    ".setOutputCol(\"token\")\\\n",
    ".setTargetPattern(\"\\S+\")\\\n",
    ".addInfixPattern(\"(/)(\\\\p{Alpha}+)\")\\\n",
    ".addInfixPattern(\"(\\\\p{Alpha}+)(/)(\\\\p{Alpha}+)\")\\\n",
    ".addInfixPattern(\"(\\\\p{Alpha}+)(\\\\.)(\\\\p{Upper}\\\\p{Alpha}+)\")\\\n",
    ".addInfixPattern(\"(.+)(\\\\.)\\\\z\")\\\n",
    ".addInfixPattern(\"(.+)([,:/])\\\\z\")\\\n",
    ".addInfixPattern(\"(\\\\()(.+)(\\\\))\")\\\n",
    ".addInfixPattern(\"(\\\\()(.+)\")\\\n",
    ".addInfixPattern(\"(.+)(\\\\))\")\\\n",
    ".addException(\"New York\")\n",
    "\n",
    "# pipeline\n",
    "pipeline1 =  Pipeline().setStages([document_assembler,\n",
    "                                  sentence_detector,\n",
    "                                  tokenizerS, \n",
    "                                  spell_checker\n",
    "                                 ])\n",
    "\n",
    "model1 = pipeline1.fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'document': [\"My friend moved to New York. She likes it. Frank visited New York, and didn't like it.\"],\n",
       " 'sentence': ['My friend moved to New York.',\n",
       "  'She likes it.',\n",
       "  \"Frank visited New York, and didn't like it.\"],\n",
       " 'token': ['My',\n",
       "  'friend',\n",
       "  'moved',\n",
       "  'to',\n",
       "  'New York.',\n",
       "  'She',\n",
       "  'likes',\n",
       "  'it',\n",
       "  '.',\n",
       "  'Frank',\n",
       "  'visited',\n",
       "  'and',\n",
       "  \"didn't\",\n",
       "  'like',\n",
       "  'it',\n",
       "  '.'],\n",
       " 'spell': ['and',\n",
       "  'is',\n",
       "  'and',\n",
       "  'in',\n",
       "  'the',\n",
       "  'it',\n",
       "  '.',\n",
       "  'the',\n",
       "  'is',\n",
       "  'it',\n",
       "  '.',\n",
       "  '.',\n",
       "  'and',\n",
       "  'one',\n",
       "  'to',\n",
       "  'New York.']}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lp1 = LightPipeline(model1)\n",
    "lp1.annotate(\"My friend moved to New York. She likes it. Frank visited New York, and didn't like it.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
